import os
import sys
from datetime import datetime, timedelta
import glob

# Projekt gy√∂k√©r k√∂nyvt√°r hozz√°ad√°sa
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.db import get_db_session
from database.models import Article, ProcessingLog, SiteStats
from config.settings import AUDIO_DIR

def cleanup_old_articles(days_old=30):
    """R√©gi cikkek t√∂rl√©se (csak a nagyon r√©giek)"""
    db = get_db_session()
    
    try:
        cutoff_date = datetime.now() - timedelta(days=days_old)
        
        # R√©gi cikkek lek√©rdez√©se
        old_articles = db.query(Article).filter(
            Article.created_at < cutoff_date
        ).all()
        
        deleted_count = 0
        
        for article in old_articles:
            try:
                # Kapcsol√≥d√≥ hangf√°jl t√∂rl√©se
                if article.audio_filename:
                    audio_path = os.path.join(AUDIO_DIR, article.audio_filename)
                    if os.path.exists(audio_path):
                        os.remove(audio_path)
                
                # Cikk t√∂rl√©se adatb√°zisb√≥l
                db.delete(article)
                deleted_count += 1
                
            except Exception as e:
                print(f"‚ö†Ô∏è Cikk t√∂rl√©si hiba: {str(e)}")
                continue
        
        db.commit()
        
        print(f"üóëÔ∏è {deleted_count} r√©gi cikk t√∂r√∂lve ({days_old} napn√°l r√©gebbiek)")
        return deleted_count
        
    except Exception as e:
        print(f"‚ùå Cikk cleanup hiba: {str(e)}")
        db.rollback()
        return 0
    finally:
        db.close()

def cleanup_old_logs(days_old=7):
    """R√©gi log bejegyz√©sek t√∂rl√©se"""
    db = get_db_session()
    
    try:
        cutoff_date = datetime.now() - timedelta(days=days_old)
        
        deleted_count = db.query(ProcessingLog).filter(
            ProcessingLog.timestamp < cutoff_date
        ).delete()
        
        db.commit()
        
        print(f"üóëÔ∏è {deleted_count} r√©gi log bejegyz√©s t√∂r√∂lve")
        return deleted_count
        
    except Exception as e:
        print(f"‚ùå Log cleanup hiba: {str(e)}")
        db.rollback()
        return 0
    finally:
        db.close()

def cleanup_orphaned_audio_files():
    """√Årva hangf√°jlok t√∂rl√©se (adatb√°zisban nem szerepl≈ë f√°jlok)"""
    db = get_db_session()
    
    try:
        # Adatb√°zisban szerepl≈ë hangf√°jlok
        db_audio_files = set()
        articles_with_audio = db.query(Article).filter(
            Article.audio_filename.isnot(None)
        ).all()
        
        for article in articles_with_audio:
            if article.audio_filename:
                db_audio_files.add(article.audio_filename)
        
        # Fizikai hangf√°jlok a mapp√°ban
        if not os.path.exists(AUDIO_DIR):
            print("üìÅ Audio mappa nem l√©tezik")
            return 0
        
        physical_files = set()
        for filename in os.listdir(AUDIO_DIR):
            if filename.endswith('.mp3'):
                physical_files.add(filename)
        
        # √Årva f√°jlok (fizikailag l√©teznek, de adatb√°zisban nincsenek)
        orphaned_files = physical_files - db_audio_files
        
        deleted_count = 0
        for filename in orphaned_files:
            try:
                file_path = os.path.join(AUDIO_DIR, filename)
                os.remove(file_path)
                deleted_count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è √Årva f√°jl t√∂rl√©si hiba {filename}: {str(e)}")
                continue
        
        print(f"üóëÔ∏è {deleted_count} √°rva hangf√°jl t√∂r√∂lve")
        return deleted_count
        
    except Exception as e:
        print(f"‚ùå √Årva f√°jl cleanup hiba: {str(e)}")
        return 0
    finally:
        db.close()

def cleanup_log_files(days_old=14):
    """R√©gi log f√°jlok t√∂rl√©se"""
    try:
        log_dir = "data/logs"
        if not os.path.exists(log_dir):
            return 0
        
        cutoff_time = datetime.now() - timedelta(days=days_old)
        deleted_count = 0
        
        for log_file in glob.glob(os.path.join(log_dir, "*.log")):
            try:
                file_mtime = datetime.fromtimestamp(os.path.getmtime(log_file))
                
                if file_mtime < cutoff_time:
                    os.remove(log_file)
                    deleted_count += 1
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Log f√°jl t√∂rl√©si hiba {log_file}: {str(e)}")
                continue
        
        print(f"üóëÔ∏è {deleted_count} r√©gi log f√°jl t√∂r√∂lve")
        return deleted_count
        
    except Exception as e:
        print(f"‚ùå Log f√°jl cleanup hiba: {str(e)}")
        return 0

def optimize_database():
    """Adatb√°zis optimaliz√°l√°s (SQLite VACUUM)"""
    try:
        from database.db import engine
        
        # SQLite VACUUM parancs
        with engine.connect() as conn:
            conn.execute("VACUUM")
        
        print("üîß Adatb√°zis optimaliz√°lva (VACUUM)")
        return True
        
    except Exception as e:
        print(f"‚ùå Adatb√°zis optimaliz√°l√°si hiba: {str(e)}")
        return False

def update_site_stats():
    """Oldal statisztik√°k friss√≠t√©se"""
    db = get_db_session()
    
    try:
        from sqlalchemy import func
        
        # Mai statisztik√°k
        today = datetime.now().date()
        
        # Cikkek sz√°ma
        total_articles = db.query(Article).count()
        
        # Mai n√©zetts√©g (egyszer≈± becsl√©s - ezt val√≥s analytics-szel kell helyettes√≠teni)
        daily_views = db.query(func.sum(Article.view_count)).scalar() or 0
        daily_audio_plays = db.query(func.sum(Article.audio_play_count)).scalar() or 0
        
        # Top kateg√≥ria
        top_category = db.query(
            Article.category,
            func.count(Article.id).label('count')
        ).group_by(Article.category).order_by(
            func.count(Article.id).desc()
        ).first()
        
        top_category_name = top_category[0] if top_category else "general"
        
        # Statisztika ment√©s
        stat = SiteStats(
            total_articles=total_articles,
            daily_views=daily_views,
            daily_audio_plays=daily_audio_plays,
            top_category=top_category_name,
            unique_visitors=0  # Ezt Google Analytics-b≈ël kellene venni
        )
        
        db.add(stat)
        db.commit()
        
        print(f"üìä Statisztik√°k friss√≠tve: {total_articles} cikk, {daily_views} n√©zetts√©g")
        return True
        
    except Exception as e:
        print(f"‚ùå Statisztika friss√≠t√©si hiba: {str(e)}")
        db.rollback()
        return False
    finally:
        db.close()

def cleanup_old_data():
    """Teljes cleanup folyamat"""
    print(f"\nüßπ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - Cleanup ind√≠t√°sa")
    
    total_operations = 0
    
    # 1. R√©gi cikkek t√∂rl√©se (30 napn√°l r√©gebbiek)
    total_operations += cleanup_old_articles(days_old=30)
    
    # 2. R√©gi logok t√∂rl√©se (7 napn√°l r√©gebbiek)
    total_operations += cleanup_old_logs(days_old=7)
    
    # 3. √Årva hangf√°jlok t√∂rl√©se
    total_operations += cleanup_orphaned_audio_files()
    
    # 4. R√©gi log f√°jlok t√∂rl√©se
    total_operations += cleanup_log_files(days_old=14)
    
    # 5. Adatb√°zis optimaliz√°l√°s
    if optimize_database():
        total_operations += 1
    
    # 6. Statisztik√°k friss√≠t√©se
    if update_site_stats():
        total_operations += 1
    
    print(f"‚úÖ Cleanup befejezve: {total_operations} m≈±velet v√©grehajtva")
    return total_operations

def main():
    """Cleanup k√©zi futtat√°shoz"""
    cleanup_old_data()

if __name__ == "__main__":
    main()